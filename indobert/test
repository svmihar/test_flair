 python run_language_modeling.py --train_data_file /root/.train_lm/guede..txt --output_dir ./indoberto-small-v1 --model_type roberta --mlm --config_name ./berto --tokenizer_name ./berto --do_train --learning_rate 1e-4 --num_train_epochs 1 --save_total_limit 2 --save_steps 2000 --per_gpu_train_batch_size 16 --seed 42
